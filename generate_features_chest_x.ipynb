{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This notebook generates the features of chestx using the pretrained densenet arcface model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_id = 0\n",
    "\n",
    "image_size = 512\n",
    "seed = 42\n",
    "batch_size = 64\n",
    "n_epochs = 25\n",
    "warmup_factor = 10\n",
    "num_workers = 24 \n",
    "device_id = 0\n",
    "\n",
    "data_dir = 'train'\n",
    "enet_type = 'densenet121'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from efficientnet_pytorch import model as enet\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import albumentations\n",
    "import geffnet\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import timm\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from warnings import filterwarnings\n",
    "import neptune\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "import glob\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device('cuda') \n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f'Setting all seeds to be {seed} to reproduce...')\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_features(test_loader):\n",
    "    model.eval()\n",
    "    bar = tqdm(test_loader)\n",
    "    \n",
    "    FEAS = []\n",
    "    TARGETS = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images) in enumerate(bar):\n",
    "\n",
    "            images = images.to(device)\n",
    "\n",
    "            features = model(images)\n",
    "\n",
    "            FEAS += [features.detach().cpu()]\n",
    "\n",
    "    FEAS = torch.cat(FEAS).cpu().numpy()\n",
    "    \n",
    "    return FEAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RANZERDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform=None):\n",
    "        \n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.loc[index]\n",
    "        img = cv2.imread(row.file_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            res = self.transform(image=img)\n",
    "            img = res['image']\n",
    "                \n",
    "        img = img.astype(np.float32)\n",
    "        img = img.transpose(2,0,1)\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            return torch.tensor(img).float()\n",
    "        else:\n",
    "            return torch.tensor(img).float(), torch.tensor(row.PatientID).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_test = albumentations.Compose([\n",
    "    albumentations.JpegCompression(90, 90, p=1),\n",
    "    albumentations.Resize(image_size, image_size),\n",
    "    albumentations.Normalize()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcModule(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=10, m=0):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_normal_(self.weight)\n",
    "\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = torch.tensor(math.cos(math.pi - m))\n",
    "        self.mm = torch.tensor(math.sin(math.pi - m) * m)\n",
    "\n",
    "    def forward(self, inputs, labels):\n",
    "        cos_th = F.linear(inputs, F.normalize(self.weight))\n",
    "        cos_th = cos_th.clamp(-1, 1)\n",
    "        sin_th = torch.sqrt(1.0 - torch.pow(cos_th, 2))\n",
    "        cos_th_m = cos_th * self.cos_m - sin_th * self.sin_m\n",
    "        # print(type(cos_th), type(self.th), type(cos_th_m), type(self.mm))\n",
    "        cos_th_m = torch.where(cos_th > self.th, cos_th_m, cos_th - self.mm)\n",
    "\n",
    "        cond_v = cos_th - self.th\n",
    "        cond = cond_v <= 0\n",
    "        cos_th_m[cond] = (cos_th - self.mm)[cond]\n",
    "\n",
    "        if labels.dim() == 1:\n",
    "            labels = labels.unsqueeze(-1)\n",
    "        onehot = torch.zeros(cos_th.size()).cuda()\n",
    "        labels = labels.type(torch.LongTensor).cuda()\n",
    "        onehot.scatter_(1, labels, 1.0)\n",
    "        outputs = onehot * cos_th_m + (1.0 - onehot) * cos_th\n",
    "        outputs = outputs * self.s\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricLearningModel(nn.Module):\n",
    "\n",
    "    def __init__(self, channel_size, out_feature, dropout=0.5, backbone='densenet121', pretrained=True):\n",
    "        super(MetricLearningModel, self).__init__()\n",
    "        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n",
    "        self.channel_size = channel_size\n",
    "        self.out_feature = out_feature\n",
    "        self.in_features = self.backbone.classifier.in_features\n",
    "        self.margin = ArcModule(in_features=self.channel_size, out_features = self.out_feature)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_features)\n",
    "        self.dropout = nn.Dropout2d(dropout, inplace=True)\n",
    "        self.fc1 = nn.Linear(self.in_features * 16 * 16 , self.channel_size)\n",
    "        self.bn2 = nn.BatchNorm1d(self.channel_size)\n",
    "        \n",
    "    def forward(self, x, labels=None):\n",
    "        features = self.backbone.features(x)\n",
    "        features = self.bn1(features)\n",
    "        features = self.dropout(features)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        features = self.fc1(features)\n",
    "        features = self.bn2(features)\n",
    "        features = F.normalize(features)\n",
    "        if labels is not None:\n",
    "            return self.margin(features, labels)\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('chestx/Data_Entry_2017.csv')\n",
    "df_test['file_path'] = sorted(glob.glob('chestx/images_*/*/*'))\n",
    "model = MetricLearningModel(512, df_test['Patient ID'].nunique())\n",
    "model.load_state_dict(torch.load('weights/dense121_feature_extractor.pth', map_location=f'cuda:{device_id}'))\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = RANZERDataset(df_test, 'test', transform=transforms_test)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEAS = generate_test_features(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('chest_x_features.npy', FEAS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
